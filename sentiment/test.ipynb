{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thanh\\anaconda3\\envs\\vlsp2018\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from train_sentiment import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [2, 2, 2, 2],\n",
       "        [3, 3, 3, 3],\n",
       "        [4, 4, 4, 4],\n",
       "        [5, 5, 5, 5]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 2, 3])\n",
    "a.unsqueeze(1).expand(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Instructor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/181 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2701, 0.1970, 0.2660, 0.2669],\n",
      "        [0.2335, 0.1783, 0.2551, 0.3330],\n",
      "        [0.2906, 0.2064, 0.2426, 0.2604],\n",
      "        [0.2089, 0.1646, 0.2395, 0.3870],\n",
      "        [0.2627, 0.2531, 0.2296, 0.2546],\n",
      "        [0.2129, 0.2040, 0.2878, 0.2953],\n",
      "        [0.2064, 0.1832, 0.2819, 0.3285],\n",
      "        [0.1714, 0.1863, 0.2687, 0.3736],\n",
      "        [0.2547, 0.1901, 0.2238, 0.3314],\n",
      "        [0.2056, 0.1864, 0.2725, 0.3356],\n",
      "        [0.2602, 0.1882, 0.2480, 0.3036],\n",
      "        [0.2104, 0.1915, 0.2543, 0.3438],\n",
      "        [0.2149, 0.1747, 0.2091, 0.4013],\n",
      "        [0.2023, 0.2105, 0.2966, 0.2906],\n",
      "        [0.2074, 0.2074, 0.2873, 0.2979],\n",
      "        [0.2291, 0.2000, 0.2470, 0.3238]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2167, 0.2647, 0.2750, 0.2435],\n",
      "        [0.2287, 0.2599, 0.2581, 0.2534],\n",
      "        [0.2347, 0.2506, 0.2236, 0.2910],\n",
      "        [0.1701, 0.3390, 0.2354, 0.2555],\n",
      "        [0.2986, 0.2353, 0.2419, 0.2241],\n",
      "        [0.1873, 0.2602, 0.3053, 0.2472],\n",
      "        [0.2344, 0.2715, 0.2665, 0.2275],\n",
      "        [0.2484, 0.2415, 0.2537, 0.2565],\n",
      "        [0.2546, 0.2477, 0.2774, 0.2203],\n",
      "        [0.2809, 0.2674, 0.2186, 0.2331],\n",
      "        [0.2649, 0.2574, 0.2541, 0.2236],\n",
      "        [0.2215, 0.2577, 0.2372, 0.2836],\n",
      "        [0.2066, 0.2648, 0.2615, 0.2671],\n",
      "        [0.2447, 0.2336, 0.2151, 0.3067],\n",
      "        [0.2360, 0.2545, 0.2658, 0.2437],\n",
      "        [0.2704, 0.2339, 0.2178, 0.2779]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2421, 0.2767, 0.2716, 0.2096],\n",
      "        [0.2074, 0.2187, 0.2770, 0.2969],\n",
      "        [0.2256, 0.2424, 0.2561, 0.2760],\n",
      "        [0.2334, 0.2641, 0.2406, 0.2619],\n",
      "        [0.2766, 0.2162, 0.2769, 0.2304],\n",
      "        [0.1887, 0.2654, 0.2333, 0.3126],\n",
      "        [0.2197, 0.2492, 0.2779, 0.2532],\n",
      "        [0.2719, 0.1885, 0.2959, 0.2436],\n",
      "        [0.2194, 0.2299, 0.2622, 0.2886],\n",
      "        [0.2381, 0.2321, 0.2378, 0.2920],\n",
      "        [0.2564, 0.2265, 0.2489, 0.2681],\n",
      "        [0.2357, 0.2037, 0.3028, 0.2578],\n",
      "        [0.2119, 0.3025, 0.2434, 0.2422],\n",
      "        [0.2887, 0.2095, 0.2648, 0.2369],\n",
      "        [0.2109, 0.2214, 0.2752, 0.2925],\n",
      "        [0.2786, 0.2596, 0.2483, 0.2135]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2542, 0.2663, 0.2082, 0.2712],\n",
      "        [0.2906, 0.2487, 0.2099, 0.2507],\n",
      "        [0.2467, 0.2686, 0.2196, 0.2651],\n",
      "        [0.2251, 0.2522, 0.2329, 0.2899],\n",
      "        [0.2526, 0.2481, 0.2250, 0.2743],\n",
      "        [0.2566, 0.2233, 0.2392, 0.2809],\n",
      "        [0.2116, 0.2398, 0.2875, 0.2610],\n",
      "        [0.2309, 0.2781, 0.2279, 0.2631],\n",
      "        [0.1944, 0.2358, 0.3014, 0.2684],\n",
      "        [0.2509, 0.2243, 0.2693, 0.2555],\n",
      "        [0.2552, 0.2083, 0.2768, 0.2598],\n",
      "        [0.2275, 0.2592, 0.2074, 0.3059],\n",
      "        [0.2847, 0.2876, 0.1925, 0.2352],\n",
      "        [0.2298, 0.2792, 0.2275, 0.2635],\n",
      "        [0.2709, 0.2338, 0.2412, 0.2540],\n",
      "        [0.2538, 0.2566, 0.2353, 0.2542]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[0.2548, 0.2421, 0.2228, 0.2803],\n",
      "        [0.2139, 0.2982, 0.2128, 0.2750],\n",
      "        [0.2069, 0.2303, 0.2787, 0.2841],\n",
      "        [0.1991, 0.2904, 0.2424, 0.2681],\n",
      "        [0.2497, 0.2394, 0.2254, 0.2855],\n",
      "        [0.2937, 0.2553, 0.2365, 0.2146],\n",
      "        [0.2200, 0.2894, 0.1977, 0.2929],\n",
      "        [0.2308, 0.2918, 0.1917, 0.2857],\n",
      "        [0.2339, 0.2968, 0.2234, 0.2460],\n",
      "        [0.2587, 0.2615, 0.2567, 0.2231],\n",
      "        [0.2365, 0.2695, 0.2121, 0.2819],\n",
      "        [0.2318, 0.2408, 0.2310, 0.2964],\n",
      "        [0.2429, 0.2759, 0.2103, 0.2709],\n",
      "        [0.2166, 0.2836, 0.2199, 0.2799],\n",
      "        [0.2842, 0.2265, 0.2152, 0.2741],\n",
      "        [0.2272, 0.3249, 0.2233, 0.2246]], device='cuda:0',\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 2., 0., 3., 1., 0., 0., 1., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([1., 1., 1., 1., 1., 0., 1., 1., 1., 2., 1., 0., 1., 1., 2., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([3., 1., 0., 1., 0., 0., 0., 3., 0., 0., 0., 0., 0., 1., 0., 3.],\n",
      "       device='cuda:0')\n",
      "tensor([[3., 3., 3., 3.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [3., 3., 3., 3.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [3., 3., 3., 3.]], device='cuda:0')\n",
      "tensor([0., 0., 0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n",
      "tensor([1., 0., 0., 0., 0., 2., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0.],\n",
      "       device='cuda:0')\n",
      "tensor([[1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [2., 2., 2., 2.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsqueeze() missing 1 required positional arguments: \"dim\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thanh\\Documents\\GitHub\\ABSA\\sentiment\\train_sentiment.py:85\u001b[0m, in \u001b[0;36mInstructor.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_train[:, i])\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_train[:, i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 85\u001b[0m losses \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlosses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[43m          \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_classes\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# for i in range(self.num_classes):\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m#     totol_loss[i] += losses[i].item() * self.batch_size\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\thanh\\Documents\\GitHub\\ABSA\\sentiment\\train_sentiment.py:85\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_train[:, i])\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28mprint\u001b[39m(y_train[:, i]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m---> 85\u001b[0m losses \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlosses[i](outputs[i]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), \u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexpand(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[0;32m     86\u001b[0m           \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_classes)]\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# for i in range(self.num_classes):\u001b[39;00m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m#     totol_loss[i] += losses[i].item() * self.batch_size\u001b[39;00m\n\u001b[0;32m     90\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     97\u001b[0m \n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# torch.nn.utils.clip_grad_norm_(self.model.parameters(), 1.0)\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[1;31mTypeError\u001b[0m: unsqueeze() missing 1 required positional arguments: \"dim\""
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 / 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/181 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax(\n",
      "  dim=tensor([[ 0.0214, -0.2941,  0.0063,  0.0097],\n",
      "          [-0.0914, -0.3610, -0.0028,  0.2636],\n",
      "          [ 0.1294, -0.2124, -0.0511,  0.0197],\n",
      "          [-0.2365, -0.4749, -0.0996,  0.3801],\n",
      "          [ 0.0390,  0.0016, -0.0959,  0.0076],\n",
      "          [-0.3107, -0.3532, -0.0093,  0.0164],\n",
      "          [-0.2999, -0.4189,  0.0117,  0.1649],\n",
      "          [-0.5925, -0.5090, -0.1426,  0.1870],\n",
      "          [-0.0757, -0.3683, -0.2050,  0.1877],\n",
      "          [-0.3895, -0.4874, -0.1078,  0.1007],\n",
      "          [-0.0940, -0.4181, -0.1419,  0.0603],\n",
      "          [-0.3068, -0.4010, -0.1177,  0.1840],\n",
      "          [-0.0125, -0.2192, -0.0398,  0.6122],\n",
      "          [-0.1810, -0.1412,  0.2016,  0.1813],\n",
      "          [-0.2038, -0.2040,  0.1218,  0.1580],\n",
      "          [-0.1890, -0.3248, -0.1139,  0.1568]], device='cuda:0',\n",
      "         grad_fn=<AddmmBackward0>)\n",
      ")\n",
      "Softmax(\n",
      "  dim=tensor([[-0.0819,  0.1182,  0.1564,  0.0346],\n",
      "          [-0.0045,  0.1233,  0.1163,  0.0982],\n",
      "          [-0.0153,  0.0500, -0.0639,  0.1997],\n",
      "          [-0.3648,  0.3247, -0.0402,  0.0419],\n",
      "          [ 0.0539, -0.1843, -0.1567, -0.2331],\n",
      "          [-0.3187,  0.0101,  0.1699, -0.0414],\n",
      "          [-0.0007,  0.1463,  0.1278, -0.0307],\n",
      "          [ 0.1040,  0.0757,  0.1251,  0.1360],\n",
      "          [ 0.1380,  0.1108,  0.2239, -0.0066],\n",
      "          [ 0.0981,  0.0486, -0.1529, -0.0886],\n",
      "          [ 0.1106,  0.0820,  0.0692, -0.0587],\n",
      "          [-0.1207,  0.0307, -0.0522,  0.1264],\n",
      "          [-0.0705,  0.1776,  0.1648,  0.1862],\n",
      "          [ 0.0187, -0.0277, -0.1103,  0.2446],\n",
      "          [-0.0547,  0.0210,  0.0642, -0.0226],\n",
      "          [ 0.0653, -0.0796, -0.1508,  0.0927]], device='cuda:0',\n",
      "         grad_fn=<AddmmBackward0>)\n",
      ")\n",
      "Softmax(\n",
      "  dim=tensor([[-0.0379,  0.0956,  0.0769, -0.1819],\n",
      "          [-0.2740, -0.2211,  0.0154,  0.0847],\n",
      "          [-0.1733, -0.1015, -0.0464,  0.0285],\n",
      "          [-0.1091,  0.0147, -0.0784,  0.0063],\n",
      "          [ 0.1946, -0.0516,  0.1957,  0.0118],\n",
      "          [-0.3503, -0.0095, -0.1385,  0.1544],\n",
      "          [-0.1063,  0.0198,  0.1289,  0.0358],\n",
      "          [ 0.1859, -0.1804,  0.2704,  0.0756],\n",
      "          [-0.1162, -0.0696,  0.0618,  0.1579],\n",
      "          [ 0.0610,  0.0357,  0.0599,  0.2652],\n",
      "          [ 0.0524, -0.0717,  0.0228,  0.0971],\n",
      "          [-0.0977, -0.2434,  0.1530, -0.0081],\n",
      "          [-0.2722,  0.0840, -0.1335, -0.1382],\n",
      "          [ 0.1001, -0.2204,  0.0137, -0.0975],\n",
      "          [-0.2276, -0.1787,  0.0388,  0.0995],\n",
      "          [ 0.0463, -0.0245, -0.0687, -0.2198]], device='cuda:0',\n",
      "         grad_fn=<AddmmBackward0>)\n",
      ")\n",
      "Softmax(\n",
      "  dim=tensor([[-3.9865e-02,  6.5067e-03, -2.3945e-01,  2.4803e-02],\n",
      "          [ 1.8889e-01,  3.3259e-02, -1.3637e-01,  4.1084e-02],\n",
      "          [-2.4582e-02,  6.0636e-02, -1.4075e-01,  4.7598e-02],\n",
      "          [-1.5447e-01, -4.0829e-02, -1.2043e-01,  9.8609e-02],\n",
      "          [-5.3655e-02, -7.1400e-02, -1.6903e-01,  2.8864e-02],\n",
      "          [ 6.7180e-02, -7.1597e-02, -2.8781e-03,  1.5785e-01],\n",
      "          [-1.2232e-01,  2.8347e-03,  1.8417e-01,  8.7418e-02],\n",
      "          [-4.0900e-03,  1.8198e-01, -1.7056e-02,  1.2643e-01],\n",
      "          [-1.6028e-01,  3.2414e-02,  2.7799e-01,  1.6205e-01],\n",
      "          [ 2.9230e-02, -8.2993e-02,  9.9960e-02,  4.7531e-02],\n",
      "          [ 9.7550e-04, -2.0217e-01,  8.2192e-02,  1.9019e-02],\n",
      "          [-1.4530e-01, -1.5182e-02, -2.3812e-01,  1.5070e-01],\n",
      "          [ 2.3107e-01,  2.4097e-01, -1.6027e-01,  4.0070e-02],\n",
      "          [-6.5515e-02,  1.2916e-01, -7.5463e-02,  7.1268e-02],\n",
      "          [ 2.0190e-01,  5.4537e-02,  8.5792e-02,  1.3756e-01],\n",
      "          [-1.7986e-03,  9.2447e-03, -7.7311e-02, -7.8782e-05]], device='cuda:0',\n",
      "         grad_fn=<AddmmBackward0>)\n",
      ")\n",
      "Softmax(\n",
      "  dim=tensor([[ 0.0826,  0.0316, -0.0514,  0.1782],\n",
      "          [-0.0866,  0.2456, -0.0919,  0.1647],\n",
      "          [-0.0518,  0.0553,  0.2461,  0.2652],\n",
      "          [-0.3122,  0.0651, -0.1152, -0.0147],\n",
      "          [ 0.0349, -0.0074, -0.0677,  0.1687],\n",
      "          [ 0.3060,  0.1659,  0.0894, -0.0077],\n",
      "          [ 0.0283,  0.3028, -0.0784,  0.3147],\n",
      "          [-0.0162,  0.2183, -0.2015,  0.1973],\n",
      "          [-0.0789,  0.1593, -0.1248, -0.0285],\n",
      "          [ 0.1583,  0.1692,  0.1506,  0.0102],\n",
      "          [ 0.0629,  0.1934, -0.0463,  0.2383],\n",
      "          [-0.0140,  0.0241, -0.0173,  0.2318],\n",
      "          [ 0.1495,  0.2768,  0.0055,  0.2587],\n",
      "          [-0.0547,  0.2145, -0.0396,  0.2016],\n",
      "          [ 0.0731, -0.1537, -0.2049,  0.0371],\n",
      "          [-0.1934,  0.1643, -0.2106, -0.2047]], device='cuda:0',\n",
      "         grad_fn=<AddmmBackward0>)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\thanh\\Documents\\GitHub\\ABSA\\sentiment\\train_sentiment.py:101\u001b[0m, in \u001b[0;36mInstructor.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[38;5;66;03m# self.scheduler.step()\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m totol_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 101\u001b[0m     totol_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpred\u001b[49m\n\u001b[0;32m    102\u001b[0m     totol_label \u001b[38;5;241m=\u001b[39m y_train\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlsp2018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
